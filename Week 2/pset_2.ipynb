{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### NX-414: Brain-like computation and intelligence, Spring 2023\n",
    "\n",
    "Notebook prepared by Bartlomiej Borzyszkowski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc": true
   },
   "source": [
    "# Week 2 - Learning a sparse code for natural images\n",
    "### Table of Contents<span class=\"tocSkip\"></span>\n",
    "<div class=\"toc\"><ul class=\"toc-item\">\n",
    "    <li><span><a href=\"#1.-Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1.&nbsp;&nbsp;</span>Introduction</a></span></li>\n",
    "    <li><span><a href=\"#2.-Image-representation\" data-toc-modified-id=\"Image-representation-2\"><span class=\"toc-item-num\">2.&nbsp;&nbsp;</span>Image representation</a></span></li>\n",
    "    <li><span><a href=\"#3.-Principal-Components-Analysis-(PCA)\" data-toc-modified-id=\"Principal-Components-Analysis-(PCA)-3\"><span class=\"toc-item-num\">3.&nbsp;&nbsp;</span>Principal Components Analysis (PCA)</a></span></li>\n",
    "    <li><span><a href=\"#4.-Sparse-coding-network\" data-toc-modified-id=\"Sparse-coding-network-4\"><span class=\"toc-item-num\">4.&nbsp;&nbsp;</span>Sparse coding network</a></span></li> \n",
    "    <li><span><a href=\"#5.-Run-simulation\" data-toc-modified-id=\"Run-simulation-5\"><span class=\"toc-item-num\">5.&nbsp;&nbsp;</span>Run simulation</a></span></li> \n",
    "    <li><span><a href=\"#6.-Evaluate-performance\" data-toc-modified-id=\"Evaluate-performance-6\"><span class=\"toc-item-num\">6.&nbsp;&nbsp;</span>Evaluate performance</a></span></li> \n",
    "    <li><span><a href=\"#7.-Conclusion\" data-toc-modified-id=\"Conclusion-7\"><span class=\"toc-item-num\">7.&nbsp;&nbsp;</span>Conclusion</a></span></li>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "In this exercise, we will study a theory for how the visual system might learn to represent visual information. The visual system must extract useful information from the complex and highly redundant visual input it receives. The receptive fields of simple cells in the primary visual cortex (V1) can be characterized as being spatially localized, oriented, and bandpass. This means that simple cells are sensitive to visual stimuli presented at a specific location and orientation in the visual field. They are also selective for a range of spatial frequencies. \n",
    "\n",
    "We aim to understand response properties of visual neurons by considering their relationship to the statistical structure of natural images in terms of efficient coding. To accomplish this, we will consider that the visual system learns a \"sparse code\" for natural images. A sparse code is one in which only a small number of neurons in V1 are active at any given time, meaning that the neurons only respond to certain features or patterns in the image.\n",
    "\n",
    "The exercise is based on the work by [Olshausen, B. A., & Field, D. J. (1996). Emergence of simple-cell receptive field properties by learning a sparse code for natural images. Nature, 381(6583), 607–609.](https://www.nature.com/articles/381607a0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Image representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We start with the assumption that an image $I(x,y)$ can be represented as a linear superposition of (not necessarily\n",
    "orthogonal) basis functions $\\phi_i(x, y)$:\n",
    "<p style=\"text-align: center;\">$I(x,y) = \\sum_{i} a_i \\phi_i(x, y)$</p>\n",
    "\n",
    "The image code is determined by the choice of basis functions $\\phi_i$. The coefficients $a_i$ are dynamic variables that change from one\n",
    "image to the next. \n",
    "\n",
    "##### Run the code below to import the requirements:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import external packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.io as sio\n",
    "import cv2\n",
    "\n",
    "#NOTE: perhaps you need into install cv2:\n",
    "#!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "As a warmup, depict a few Gabor filter (also known as Gabor wavelet or kernel). It is a mathematical function that is used in image processing to extract features such as edges and textures from an image and describes simple cells well.\n",
    "\n",
    "\n",
    "It is a type of filter that combines a Gaussian envelope with a sinusoidal carrier wave. The Gaussian envelope determines the size and shape of the filter, while the carrier wave determines the frequency and orientation of the filter. The equation for a Gabor filter in two dimensions is:\n",
    "\n",
    "<p style=\"text-align: center;\">$G(x, y) = exp(-((x^2 + y^2) / (2 * σ^2))) * cos(2 * π * f * x + \\phi)$</p>\n",
    "\n",
    "where $x$ and $y$ are the spatial coordinates, $\\sigma$ is the standard deviation of the Gaussian function, $u$ and $v$ are the frequency vectors, and $\\phi$ is the phase offset.\n",
    "\n",
    "##### Implement four Gabor filters oriented at 0°, 45°, 90°, and 135° with parameters:\n",
    "- kernel size = (30, 30);\n",
    "- Gaussian standard deviation = 3.0;\n",
    "- wave length = 10;\n",
    "- spatial ratio = 0.5;\n",
    "- phase = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelwidth = 30 \n",
    "\n",
    "gabor = []\n",
    "for i in range(4):\n",
    "    # TODO: use OpenCV to define a Gabor Kernel with the desired parameters (~1 line):\n",
    "    gabor_kernel = \n",
    "    gabor.append(gabor_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,1+i)\n",
    "    plt.title(r\"$\\theta=$\"+str(i*45)+r\"$^\\circ$\")\n",
    "    plt.imshow(gabor[i], cmap=\"gray\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive 3D plot (as shown in the lecture)\n",
    "\n",
    "%matplotlib widget\n",
    "# Note: if the above line fails, try replacing `%matplotlib widget` with `%matplotlib notebook`\n",
    "\n",
    "from matplotlib import cm\n",
    "X = np.arange(kernelwidth+1)\n",
    "Y = np.arange(kernelwidth+1)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "surf = ax.plot_surface(X, Y, gabor[i], cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the code below to download the dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset from original paper source at http://www.rctn.org/bruno/sparsenet/\n",
    "# Note you can also use curl, if wget is not installed (e.g. on MacOS)\n",
    "#!curl  \"-O\" \"http://www.rctn.org/bruno/sparsenet/IMAGES.mat\"\n",
    "#!curl  \"-O\" \"http://www.rctn.org/bruno/sparsenet/IMAGES_RAW.mat\"\n",
    "!wget \"http://www.rctn.org/bruno/sparsenet/IMAGES.mat\"\n",
    "!wget \"http://www.rctn.org/bruno/sparsenet/IMAGES_RAW.mat\"\n",
    "mat_images = sio.loadmat('IMAGES.mat')\n",
    "imgs = mat_images['IMAGES']\n",
    "mat_images_raw = sio.loadmat('IMAGES_RAW.mat')\n",
    "imgs_raw = mat_images_raw['IMAGESr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the dimensions?\n",
    "np.shape(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the code below to visualize raw images from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot examle natural images\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(imgs_raw[:,:,i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "fig.suptitle(\"Natural Images\", fontsize=20)\n",
    "plt.subplots_adjust(top=0.9) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply each of the pre-defined Gabor Kernels to a single image from the dataset and visualize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_image = imgs_raw[:, :, 0]\n",
    "out = []\n",
    "for i in range(4):\n",
    "    # TODO: use OpenCV to apply each of the pre-defined Gabor Kernels to the selected single image (~1 line):\n",
    "    out_image = \n",
    "    out.append(out_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,1+i)\n",
    "    plt.title(r\"$\\theta=$\"+str(i*45)+r\"$^\\circ$\")\n",
    "    plt.imshow(out[i], cmap=\"gray\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract images patches\n",
    "\n",
    "# Simulation constants\n",
    "H, W, num_images = imgs_raw.shape\n",
    "patchs_list = []\n",
    "\n",
    "# TODO: specify the number of parameters (eg. 15000) and path size (eg. 16 x 16) (~2 lines):\n",
    "num_patches = \n",
    "w, h =\n",
    "\n",
    "\n",
    "pl=[]\n",
    "\n",
    "# Generate image patches\n",
    "for patch in tqdm(range(num_patches)):\n",
    "    # Get the coordinates of the upper left corner of for cropping images randomly.\n",
    "    beginx = np.random.randint(0, W-w-1)\n",
    "    beginy = np.random.randint(0, H-h-1)\n",
    "    \n",
    "    # TODO: Get index of a random image from the dataset (~1 line):\n",
    "    idx = \n",
    "    \n",
    "    img_cropped = imgs_raw[beginy:beginy+h, beginx:beginx+w, idx]\n",
    "    \n",
    "    \n",
    "    patchs_list.append(img_cropped.flatten())\n",
    "    \n",
    "    img_c=imgs[beginy:beginy+h, beginx:beginx+w, idx]\n",
    "    pl.append(img_c.flatten())\n",
    "    \n",
    "processed_patches=np.array(pl)\n",
    "\n",
    "patches = np.array(patchs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Principal Components Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use Principal Component Analysis (PCA), an unsupervised learning technique used to transform a set of correlated variables into a set of linearly uncorrelated variables called principal components. PCA is commonly used for dimensionality reduction, feature extraction, and data visualization.\n",
    "\n",
    "In image processing, PCA can be applied to reduce the dimensionality of an image by projecting it onto a lower-dimensional space, while preserving the most important features of the image. This is achieved by finding a set of principal components that capture the largest amount of variance in the image data. The principal components can be used to reconstruct the original image, or to extract features for image analysis.\n",
    "\n",
    "The goal is to find a set of mutually orthogonal basis functions that capture the directions of maximum variance in the data and for which the coefficients are pairwise decorrelated, $<a_ia_j> = <a_i><a_j>$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the PCA and plot the resulting filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: initialize the PCA with the given number of components (~1 line):\n",
    "pca = \n",
    "# TODO: fit the generated patches to the ICA (~1 line):\n",
    "\n",
    "# TODO: get components from the PCA (~1 line):\n",
    "pca_filters = \n",
    "\n",
    "# plot filters\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "for i in tqdm(range(n_comp)):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(np.reshape(pca_filters[i], (w, h)), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"PCA\", fontsize=20)\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that receptive fields found by PCA are not localized and the vast majority do not at all resemble cortical tuning curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Sparse coding network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a computational model to simulate the learning of a sparse code for natural images. We assume that the neurons in V1 initially have random connections to the input, and then update their connections based on a learning algorithm that encourages sparsity. \n",
    "\n",
    "The search for a sparse code can be formulated as an optimization problem by constructing the following cost function to be\n",
    "minimized: \n",
    "\n",
    "$$\n",
    "E = \\underbrace{\\left\\|\\boldsymbol{I}-\\Phi \\boldsymbol{a}\\right\\|^2}_{\\text{preserve information}} + \\lambda \\underbrace{\\sum_i S\\left(\\frac{a_i}{\\sigma}\\right)}_{\\text{sparseness of}\\ a_i} \\tag{2}\n",
    "$$\n",
    "\n",
    "where $\\lambda$ is a positive constant that determines the importance of the second term relative to the first. The first term measures how well the code describes the image, and we choose it to be the mean square of the error between the actual image and the reconstructed image. The second term assesses the sparseness of the code for a given image by assigning a cost depending on how activity is distributed among the coefficients: those representations in which activity is spread over many coefficients should incur a higher cost than those in which only a few coefficients carry the load.\n",
    "\n",
    "The value of $S(x) = |x|$. The reasoning behind this choice is that they it favours among activity states with equal variance those with the fewest number of non-zero coefficients.\n",
    "\n",
    "\n",
    "##### Implement a class for the Sparse Coding Network:\n",
    "It is a simple neural network with one hidden later. The input is a 16×16 image patch randomly cut out, which is received by 256 neurons in the input layer. Assume that the neurons in the input layer project to 25 neurons in the hidden layer that sparsely encodes the input.\n",
    "\n",
    "We will train the model using LCA (Local Competitive Algorithm), an update rule with local competition (lateral suppression) and a threshold function. More details on this model can be found in \n",
    "\n",
    "Sparse coding via thresholding and local competition in neural circuits by Rozell, Johnson, Baraniuk, and Olshausen\n",
    "https://pubmed.ncbi.nlm.nih.gov/18439138/\n",
    "\n",
    "This was also briefly mentioned in the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseCodingNetwork:\n",
    "    def __init__(self, num_inputs, num_units, batch_size, lr_a=1e-2, lr_Phi=1e-2, lmda=5e-3):\n",
    "        # TODO: initialize the learning rate of a and Phi as well as the regularization parameter (trivial, ~3 lines):\n",
    "        self.lr_a = \n",
    "        self.lr_Phi = \n",
    "        self.lmda = \n",
    "        \n",
    "        # TODO: initialize the number of inputs and units as well as the batch size (trivial, ~3 lines):\n",
    "        self.num_inputs = \n",
    "        self.num_units = \n",
    "        self.batch_size = \n",
    "        \n",
    "        # weights initialization\n",
    "        Phi = np.random.randn(self.num_inputs, self.num_units).astype(np.float32)\n",
    "        self.Phi = Phi * np.sqrt(1/self.num_units)\n",
    "        self.initialize_states()\n",
    "    \n",
    "    def initialize_states(self):\n",
    "        self.a = np.zeros((self.batch_size, self.num_units))\n",
    "        \n",
    "    def normalize_rows(self):\n",
    "        self.Phi = self.Phi / np.maximum(np.linalg.norm(self.Phi, ord=2, axis=0, keepdims=True), 1e-8)\n",
    "\n",
    "    def soft_thresholding_func(self, x, lmda):\n",
    "        \"\"\" Soft thresholding function of S(x)=|x| \"\"\" \n",
    "        return np.maximum(x - lmda, 0) - np.maximum(-x - lmda, 0)\n",
    "\n",
    "    def calculate_total_error(self, error):\n",
    "        recon_error = np.mean(error**2)\n",
    "        sparsity_a = self.lmda*np.mean(np.abs(self.a)) \n",
    "        return recon_error + sparsity_a\n",
    "        \n",
    "    def __call__(self, inputs, training=True):\n",
    "        # Updates                \n",
    "        error = inputs - self.a @ self.Phi.T\n",
    "        \n",
    "        a = self.a + self.lr_a * error @ self.Phi\n",
    "        self.a = self.soft_thresholding_func(a, self.lmda)\n",
    "        \n",
    "        if training:  \n",
    "            error = inputs - self.a @ self.Phi.T\n",
    "            dPhi = error.T @ self.a\n",
    "            self.Phi += self.lr_Phi * dPhi\n",
    "            \n",
    "        return error, self.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5. Run simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specify the simulation constants and initialize the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation constants\n",
    "H, W, num_images = imgs.shape\n",
    "\n",
    "# TODO: specify the number of iterations (eg. 100) maximum number of simulation time (eg. 1000s) and batch size (eg. 250) (design choice, ~3 lines):\n",
    "num_iter =  \n",
    "nt_max =  \n",
    "batch_size =  \n",
    "\n",
    "# TODO: specify the image patch size (eg. 16) and the number of neurons (eg. 25) (design choice, ~2 lines):\n",
    "sz =  \n",
    "num_units =  \n",
    "\n",
    "num_inputs = sz**2\n",
    "eps = 1e-2 # small value which determines convergence\n",
    "error_list = [] # List to save errors\n",
    "\n",
    "# TODO: initialize the SparseCodingNetwork with the desired numuber of inputs, units and batch size (~1 line):\n",
    "model = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implement code to run the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation\n",
    "for iter_ in tqdm(range(num_iter)):\n",
    "    # Get the coordinates of the upper left corner of cropping image randomly.\n",
    "    beginx = np.random.randint(0, W-sz, batch_size)\n",
    "    beginy = np.random.randint(0, H-sz, batch_size)\n",
    "\n",
    "    inputs_list = []\n",
    "    for i in range(batch_size):        \n",
    "        \n",
    "        # TODO: Get index of a random image from the dataset (~1 line):\n",
    "        idx = \n",
    "        \n",
    "        img = imgs[:, :, idx]\n",
    "        crop = img[beginy[i]:beginy[i]+sz, beginx[i]:beginx[i]+sz].flatten()\n",
    "        inputs_list.append(crop - np.mean(crop))\n",
    "        \n",
    "    inputs = np.array(inputs_list) # Input image patches\n",
    "    \n",
    "    # TODO: Reset (initialize) states of the model (~1 line):\n",
    "    \n",
    "    \n",
    "    # TODO: Normalize weights (rows) (~1 line):\n",
    "    \n",
    "    \n",
    "    # TODO: Initialize the a (activity of neurons) (~1 line):\n",
    "    a_tm1 = \n",
    "\n",
    "    for t in range(nt_max):\n",
    "        # TODO: Update a without update weights (set training to False) (~1 line):\n",
    "        error, a = \n",
    "        \n",
    "        # TODO: Compute the difference between current and previous a (~1 line):\n",
    "        da = \n",
    "\n",
    "        # Compute norm of a\n",
    "        da_norm = np.linalg.norm(da, ord=2) / (eps + np.linalg.norm(a_tm1, ord=2))\n",
    "        a_tm1 = a # update a_tm1\n",
    "        \n",
    "        # Check convergence of a, then update weights\n",
    "        if da_norm < eps:\n",
    "            # TODO: Update a with weights update (set training to True) (~1 line):\n",
    "            error, a = \n",
    "            break\n",
    "        \n",
    "        # If failure to convergence, break and print error\n",
    "        if t >= nt_max-2: \n",
    "            print(\"Error at patch:\", iter_)\n",
    "            print(dr_norm)\n",
    "            break\n",
    "   \n",
    "    error_list.append(model.calculate_total_error(error)) # Append errors\n",
    "\n",
    "    # Print moving average error\n",
    "    if iter_ % 100 == 99:  \n",
    "        print(\"iter: \"+str(iter_+1)+\"/\"+str(num_iter)+\", Moving error:\", np.mean(error_list[iter_-99:iter_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 6. Evaluate performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the following code to plot the error across the iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.plot(np.arange(len(error_list)), np.array(error_list))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the following code to plot the resulting receptive fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "for i in tqdm(range(num_units)):\n",
    "    plt.subplot(10, 10, i+1)\n",
    "    plt.imshow(np.reshape(model.Phi[:, i], (sz, sz)), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"Receptive fields\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The presented results show that the sparse model learns to extract simple features from natural images, these receptive fields are similar to the receptive fields of simple cells in the visual cortex. The model provides a plausible explanation for how the visual system might learn to represent complex visual information with a relatively small number of neurons. The result suggests that this type of sparse coding may be a general principle of sensory processing in the brain.\n",
    "\n",
    "For more detail on this topic, please see the source work by [Olshausen, B. A., & Field, D. J. (1996). Emergence of simple-cell receptive field properties by learning a sparse code for natural images. Nature, 381(6583), 607–609.](https://www.nature.com/articles/381607a0). \n",
    "\n",
    "##### Congratulations! You have finished this week's problem set on learning a sparse code for natural images!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "342px",
    "left": "22px",
    "top": "110px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
